{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fonnesbeck/instats_gp/blob/main/sessions/Session_1.ipynb)\n",
        "\n",
        "# Session 1: Introduction to Gaussian Processes and PyMC\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this session, you will be able to:\n",
        "\n",
        "- Understand what Bayesian non-parametric models are and how Gaussian processes fit into this framework\n",
        "- Connect the familiar concept of multivariate normal distributions to the more general idea of Gaussian processes\n",
        "- Learn the basics of PyMC and how to implement simple models\n",
        "- Understand the roles of mean and covariance functions in defining a GP's behavior\n",
        "- Build and fit your first GP model using real data\n",
        "\n",
        "## LLM-Assisted Exercises\n",
        "\n",
        "Throughout these notebooks, you'll notice sections marked with ðŸ¤–. These are **LLM-assisted exercises** where you'll practice using large language models (like ChatGPT, Claude, or your favorite coding assistant) to help you implement GP concepts. This approach reflects modern data science practice: knowing *what* you want to accomplish and *how* to verify it is often more important than memorizing every implementation detail.\n",
        "\n",
        "The exercises are designed to help you develop the skill of effectively communicating with AI assistantsâ€”a critical ability in today's data science workflow. You'll learn to write clear prompts, test implementations, and validate results, building both your GP expertise and your collaborative coding skills."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1.1: Introduction and Setup\n",
        "\n",
        "### What Does \"Non-Parametric\" Mean in a GP Context?\n",
        "\n",
        "When we talk about Gaussian processes being \"non-parametric,\" we're not saying they have no parametersâ€”that would be confusing! Instead, we mean that GPs don't assume a fixed functional form with a finite number of parameters. \n",
        "\n",
        "Think about it this way: in linear regression, you commit to a straight line (or hyperplane) defined by a slope and intercept. You're making a strong assumption about the shape of your function before seeing the data. With a GP, you're defining a *distribution over functions*. The data then tells you which functions from this distribution are most plausible.\n",
        "\n",
        "This flexibility makes GPs incredibly powerful for modeling complex, unknown relationships. The \"parameters\" in a GP are actually hyperparameters that control properties like smoothness and lengthscaleâ€”they shape the space of possible functions rather than defining a single function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pymc as pm\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import arviz as az\n",
        "import plotly.io as pio\n",
        "from scipy import stats\n",
        "\n",
        "DATA_DIR = \"../data/\"\n",
        "\n",
        "RNG = np.random.default_rng(RANDOM_SEED:= 8675309)\n",
        "\n",
        "pio.templates.default = \"plotly_white\"\n",
        "\n",
        "print(f\"PyMC version: {pm.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Polars version: {pl.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Everything should import cleanly and you should see version numbers printed above. If you encounter any import errors, make sure your environment is set up correctly with PyMC 5.16+, NumPy 2.x, and Polars 1.x.\n",
        "\n",
        "Notice that we're setting `RANDOM_SEED` right at the start. Reproducibility is crucial in Bayesian workflowsâ€”you want to be able to recreate your results exactly, especially when debugging or sharing your work with colleagues.\n",
        "\n",
        "### ArviZ for Posterior Analysis\n",
        "\n",
        "Throughout this workshop, we'll use **ArviZ first** for all posterior analysis, diagnostics, and visualization. ArviZ provides battle-tested functions for computing summaries, visualizing distributions, and performing model checking. While you could manually extract posterior samples and create custom plots, ArviZ handles edge cases correctly and provides consistent, publication-quality output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1.2: Bayesian Inference Primer\n",
        "\n",
        "Before we learn the PyMC API or dive into Gaussian processes, let's build intuition for the Bayesian framework itself. Understanding how we update beliefs with data is fundamental to everything that follows.\n",
        "\n",
        "### The Three-Step Bayesian Workflow\n",
        "\n",
        "Every Bayesian analysis follows the same three-step pattern:\n",
        "\n",
        "1. **Specify a probability model**: Assign probability distributions to all unknownsâ€”parameters, predictions, even missing data\n",
        "2. **Calculate the posterior distribution**: Update our beliefs by combining prior knowledge with observed data  \n",
        "3. **Check and interpret**: Validate the model and draw conclusions\n",
        "\n",
        "This workflow applies whether we're estimating a simple proportion or building complex Gaussian process models.\n",
        "\n",
        "### Bayes' Theorem: The Foundation\n",
        "\n",
        "At its heart, Bayesian inference is about updating beliefs with data. We start with prior knowledge (the prior), observe data (the likelihood), and combine them through multiplication to get updated knowledge (the posterior):\n",
        "\n",
        "$$P(\\theta | y) \\propto P(y | \\theta) P(\\theta)$$\n",
        "\n",
        "**Reading this equation aloud:**\n",
        "- **Posterior** âˆ **Likelihood** Ã— **Prior**\n",
        "- What we believe about $\\theta$ after seeing data is proportional to how likely the data would be under different $\\theta$ values, weighted by what we believed before\n",
        "\n",
        "This seemingly simple equation is incredibly powerful. Think of it visually: if your prior was a curve and the likelihood was another curve, the posterior is their productâ€”peaks where both agree, valleys where they disagree.\n",
        "\n",
        "The proportionality constant is just a normalization factor ensuring probabilities sum to oneâ€”important mathematically, but not essential for building intuition.\n",
        "\n",
        "### A Concrete Example: Estimating a Batting Average\n",
        "\n",
        "Let's work through a simple analytical example to see Bayesian updating in action. Imagine we want to estimate the true batting average $\\theta$ for a baseball playerâ€”the probability they get a hit in any given plate appearance.\n",
        "\n",
        "**Setup**: We observe a player get 3 hits in their first 5 plate appearances. What can we infer about their true batting average $\\theta$?\n",
        "\n",
        "**Step 1: Specify the model**\n",
        "- **Likelihood** (Binomial): Number of hits follows $\\text{Binomial}(n=5, p=\\theta)$\n",
        "- **Prior** (Beta): We start with a uniform prior, $\\text{Beta}(1, 1)$â€”maximum uncertainty about $\\theta$\n",
        "\n",
        "**Step 2: Compute the posterior**\n",
        "\n",
        "The beautiful thing about the Beta-Binomial combination is that we can calculate the posterior analyticallyâ€”no fancy algorithms needed! This is called *conjugacy*.\n",
        "\n",
        "The posterior is $\\text{Beta}(1+3, 1+2) = \\text{Beta}(4, 3)$. Notice how the parameters simply add:\n",
        "- Prior \"hits\": 1 -> Posterior: 1 + 3 = 4\n",
        "- Prior \"outs\": 1 -> Posterior: 1 + 2 = 3\n",
        "\n",
        "Let's visualize this updating process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: 3 hits from 5 plate appearances\n",
        "n, y = 5, 3\n",
        "theta = np.linspace(0, 1, 200)\n",
        "\n",
        "# Prior: Beta(1, 1) = Uniform\n",
        "prior = stats.beta.pdf(theta, 1, 1)\n",
        "\n",
        "# Likelihood: Binomial (normalized for visibility)\n",
        "likelihood = theta**y * (1-theta)**(n-y)\n",
        "likelihood = likelihood / likelihood.max()\n",
        "\n",
        "# Posterior: Beta(1+y, 1+n-y) = Beta(4, 3)\n",
        "posterior = stats.beta.pdf(theta, 1+y, 1+n-y)\n",
        "\n",
        "# Visualize\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=theta, y=prior, name='Prior',\n",
        "                         mode='lines', line=dict(color='gray', width=2, dash='dash')))\n",
        "fig.add_trace(go.Scatter(x=theta, y=likelihood, name='Likelihood (normalized)',\n",
        "                         mode='lines', line=dict(color='blue', width=2)))\n",
        "fig.add_trace(go.Scatter(x=theta, y=posterior, name='Posterior',\n",
        "                         mode='lines', line=dict(color='red', width=3)))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Bayesian Updating: Prior Ã— Likelihood = Posterior',\n",
        "    xaxis_title='Î¸ (batting average)',\n",
        "    yaxis_title='Probability Density',\n",
        "    showlegend=True\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "# Posterior mean\n",
        "posterior_mean = (1 + y) / (1 + 1 + n)\n",
        "print(f\"\\nPosterior mean: {posterior_mean:.3f}\")\n",
        "print(f\"This is between our prior mean (0.5) and the observed proportion ({y/n:.3f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice the beautiful interplay:\n",
        "\n",
        "- The **prior** (gray dashed) is flatâ€”we started with no preference for any value of $\\theta$\n",
        "- The **likelihood** (blue) peaks at the observed proportion (3/5 = 0.6)â€”this is what the data alone suggests\n",
        "- The **posterior** (red) is their product, peaked near the likelihood but slightly regularized by the prior\n",
        "\n",
        "With only 5 plate appearances, there's still substantial uncertainty. Let's see what happens as we collect more data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show how posterior narrows with more data\n",
        "# True batting average is 0.250, but we start with 3 hits in 5 at-bats (0.600)\n",
        "sample_sizes = [5, 20, 100]\n",
        "true_average = 0.250\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "for n in sample_sizes:\n",
        "    # Generate plausible number of hits given true average\n",
        "    y = RNG.binomial(n, true_average)\n",
        "    posterior = stats.beta.pdf(theta, 1+y, 1+n-y)\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=theta, y=posterior,\n",
        "        name=f'n={n}, y={y}',\n",
        "        mode='lines', line=dict(width=2)\n",
        "    ))\n",
        "\n",
        "# Add vertical line at true batting average\n",
        "fig.add_vline(x=true_average, line_dash=\"dash\", line_color=\"green\", \n",
        "              annotation_text=f\"True average: {true_average}\", \n",
        "              annotation_position=\"top right\")\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Posterior Distribution Narrows with More Data',\n",
        "    xaxis_title='Î¸ (batting average)',\n",
        "    yaxis_title='Posterior Density',\n",
        "    showlegend=True\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This progression beautifully illustrates Bayesian learning in action:\n",
        "\n",
        "- With **5 plate appearances** (3 hits), the posterior is wide and centered around 0.6â€”our small sample was misleading!\n",
        "- With **20 plate appearances** (5 hits), uncertainty decreases substantially and the posterior begins moving toward the true average\n",
        "- With **100 plate appearances** (25 hits), the posterior becomes very sharp and concentrates tightly around the true batting average of 0.250\n",
        "\n",
        "This demonstrates a crucial insight: **early observations can be misleading, but as we accumulate more data, the truth emerges**. A player going 3-for-5 in their first few at-bats might look like a .600 hitter, but by 100 at-bats, their true talent level becomes clear.\n",
        "\n",
        "The posterior mean is always a weighted average of the prior and the data, with the data getting more weight as sample size grows. This is Bayesian learning in actionâ€”prior beliefs get updated, and eventually overwhelmed, by evidence. The \"hot start\" of 3-for-5 gets appropriately downweighted as more representative data accumulates.\n",
        "\n",
        "### Why This Matters for Gaussian Processes\n",
        "\n",
        "This same Bayesian framework powers GP modeling. Instead of updating beliefs about a single parameter $\\theta$, we'll update beliefs about entire *functions*. The prior becomes a distribution over functions (specified by mean and covariance), the likelihood describes how data relates to function values, and the posterior gives us updated beliefs about which functions are plausible.\n",
        "\n",
        "But first, we need to learn how to implement Bayesian models in PyMC. Let's dive into the API with a real dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1.3: Introduction to PyMC with Real Data\n",
        "\n",
        "Now that we understand the Bayesian framework conceptually, let's learn how to implement it using PyMC. We'll start with the simplest possible model: estimating the distribution of a single continuous variable.\n",
        "\n",
        "### The Data: Baseball Launch Angles\n",
        "\n",
        "We'll use real baseball data from the `fastball_bat_angles.csv` dataset. When a batter makes contact with a fastball, the ball leaves the bat at a particular **launch angle**â€”the vertical angle relative to horizontal. Launch angle is crucial for hitting outcomes: too low and you hit a ground ball, too high and you pop out, just right and you might hit a home run.\n",
        "\n",
        "Let's focus on a single player and estimate the distribution of their launch angles. We'll use this to learn PyMC syntax before moving to more complex models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the fastball bat angle data\n",
        "df = pl.read_csv(DATA_DIR + 'fastball_bat_angles.csv')\n",
        "\n",
        "# See what batters we have\n",
        "print(\"Sample of available batters:\")\n",
        "print(df.select('batter_name').unique().head(10))\n",
        "\n",
        "# Let's focus on Bryce Harper\n",
        "harper = df.filter(pl.col('batter_name') == 'Harper, Bryce')\n",
        "print(f\"\\nBryce Harper: {harper.shape[0]} fastball contacts\")\n",
        "\n",
        "# Extract launch angles as numpy array\n",
        "launch_angles = harper['launch_angle'].to_numpy()\n",
        "\n",
        "# Visualize the distribution\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Histogram(\n",
        "    x=launch_angles,\n",
        "    nbinsx=30,\n",
        "    name='Observed Launch Angles',\n",
        "    marker_color='steelblue'\n",
        "))\n",
        "fig.update_layout(\n",
        "    title='Bryce Harper: Launch Angle Distribution',\n",
        "    xaxis_title='Launch Angle (degrees)',\n",
        "    yaxis_title='Count',\n",
        "    showlegend=False\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "print(f\"\\nSummary statistics:\")\n",
        "print(f\"Mean: {launch_angles.mean():.1f}Â°\")\n",
        "print(f\"Std Dev: {launch_angles.std():.1f}Â°\")\n",
        "print(f\"Range: [{launch_angles.min():.1f}Â°, {launch_angles.max():.1f}Â°]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The distribution looks roughly bell-shaped, though perhaps not perfectly symmetric. A normal distribution seems like a reasonable starting point.\n",
        "\n",
        "### Building Your First PyMC Model\n",
        "\n",
        "Let's estimate the mean and standard deviation of Harper's launch angle distribution. The model is simple:\n",
        "\n",
        "$$\\begin{aligned}\n",
        "\\mu &\\sim \\text{Normal}(30, 20) \\\\\n",
        "\\sigma &\\sim \\text{HalfNormal}(20) \\\\\n",
        "y_i &\\sim \\text{Normal}(\\mu, \\sigma)\n",
        "\\end{aligned}$$\n",
        "\n",
        "We're saying:\n",
        "- The mean launch angle $\\mu$ is probably around 30Â° (that's a good launch angle), but we're quite uncertain (SD of 20Â°)\n",
        "- The standard deviation $\\sigma$ is positive, probably not hugeâ€”maybe around 20Â° or less\n",
        "- Each observed launch angle is drawn from a normal distribution with these parameters\n",
        "\n",
        "Here's how to write this in PyMC:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with pm.Model() as launch_model:\n",
        "    # Priors\n",
        "    mu = pm.Normal('mu', mu=30, sigma=20)\n",
        "    sigma = pm.HalfNormal('sigma', sigma=20)\n",
        "    \n",
        "    # Likelihood\n",
        "    y_obs = pm.Normal('y', mu=mu, sigma=sigma, observed=launch_angles)\n",
        "    \n",
        "    # Sample from the posterior\n",
        "    trace = pm.sample(1000, tune=1000, nuts_sampler='nutpie',\n",
        "                      random_seed=RNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's unpack what just happened:\n",
        "\n",
        "1. `with pm.Model() as launch_model:` creates a model context. All variables defined inside this block are part of the model.\n",
        "\n",
        "2. `pm.Normal('mu', mu=30, sigma=20)` defines our prior for the mean. The first argument is the variable name, then come the parameters.\n",
        "\n",
        "3. `pm.HalfNormal('sigma', sigma=20)` defines our prior for the standard deviation. HalfNormal is like Normal but constrained to be positiveâ€”perfect for scale parameters.\n",
        "\n",
        "4. `pm.Normal('y', mu=mu, sigma=sigma, observed=launch_angles)` defines the likelihood. The `observed=` argument connects the model to our actual data.\n",
        "\n",
        "5. `pm.sample()` runs MCMC sampling to approximate the posterior distribution. We'll learn more about this laterâ€”for now, just know it's finding the parameter values most consistent with our data and priors.\n",
        "\n",
        "Now let's examine what we learned:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary table\n",
        "print(\"Posterior Summary:\")\n",
        "print(az.summary(trace, var_names=['mu', 'sigma']))\n",
        "\n",
        "# Visualize posteriors\n",
        "az.plot_posterior(trace, var_names=['mu', 'sigma']);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ArviZ's `summary` function provides comprehensive posterior statistics including:\n",
        "- **mean**: The posterior mean estimate\n",
        "- **sd**: The posterior standard deviation (uncertainty)\n",
        "- **hdi_3%** and **hdi_97%**: The 94% Highest Density Intervalâ€”the narrowest interval containing 94% of posterior probability\n",
        "- **r_hat**: Convergence diagnostic (should be < 1.01)\n",
        "- **ess_bulk** and **ess_tail**: Effective sample size metrics\n",
        "\n",
        "The `plot_posterior` function creates clean, informative visualizations showing the posterior distribution along with the mean and HDI automatically computed and displayed.\n",
        "\n",
        "Notice how much narrower the posterior is compared to our priorâ€”the data has substantially reduced our uncertainty about Harper's true mean launch angle.\n",
        "\n",
        "### Posterior Predictive Checks\n",
        "\n",
        "A crucial part of the Bayesian workflow is asking: \"If this model is correct, would it generate data that looks like what we actually observed?\" This is called a **posterior predictive check**.\n",
        "\n",
        "We'll use the posterior distributions of $\\mu$ and $\\sigma$ to simulate new datasets and compare them to our observed data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with launch_model:\n",
        "    # Sample from the posterior predictive distribution\n",
        "    trace.extend(pm.sample_posterior_predictive(trace, random_seed=RNG))\n",
        "\n",
        "# Use ArviZ's built-in posterior predictive check plot\n",
        "az.plot_ppc(trace, num_pp_samples=100);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ArviZ's `plot_ppc` function creates an intuitive visualization comparing the posterior predictive samples (multiple light curves) with the observed data (darker curve). If the model captures the data-generating process well, the observed data should look like a plausible draw from the posterior predictive distribution.\n",
        "\n",
        "In this case, the posterior predictive samples overlay nicely with the observed data, suggesting our simple normal model is a reasonable approximation. If there were systematic discrepanciesâ€”say, the observed data had heavy tails that the model couldn't captureâ€”we'd see clear differences and might consider a different likelihood (like Student's t).\n",
        "\n",
        "This workflowâ€”specify model, fit, checkâ€”is fundamental to Bayesian modeling and will be our pattern throughout this workshop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ¤– EXERCISE: Compare Launch Angles Across Batters\n",
        "\n",
        "Now that you've seen the basic workflow, practice it with different players."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use your LLM to help complete this comparison\n",
        "\n",
        "def compare_batters(batter_names, df):\n",
        "    \"\"\"\n",
        "    Fit a joint launch angle model for multiple batters and compare posteriors.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    batter_names : list of str\n",
        "        Names of batters to compare (e.g., ['Harper, Bryce', 'Alonso, Pete'])\n",
        "    df : polars DataFrame\n",
        "        The fastball bat angles dataset\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    results : fig\n",
        "        Figure object containing the forest plot comparing posterior means\n",
        "\n",
        "    \"\"\"\n",
        "    # YOUR LLM-ASSISTED CODE HERE\n",
        "    pass\n",
        "\n",
        "# Test with a few batters\n",
        "# batters = ['Harper, Bryce', 'Alonso, Pete', 'Tucker, Kyle']\n",
        "# results = compare_batters(batters, df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1.4: Multivariate Normal Models\n",
        "\n",
        "So far we've modeled single variables in isolationâ€”Harper's launch angle as a univariate distribution. But real data often contains multiple related measurements that vary together. Before we extend to Gaussian processes (which model infinite-dimensional relationships), let's see how to model joint distributions of multiple variables using the multivariate normal distribution.\n",
        "\n",
        "A **multivariate normal distribution** lets us model the joint distribution of multiple variables, capturing how they covary. This is also where PyMC's **coordinate system** shines. Coordinates (`coords`) let us give meaningful names to dimensions in our models, improving readability and enabling advanced features.\n",
        "\n",
        "### Attack Angle and Launch Angle\n",
        "\n",
        "When a batter swings, two angles matter:\n",
        "- **Attack angle**: The vertical angle of the bat's path as it moves through the hitting zone\n",
        "- **Launch angle**: The vertical angle of the ball as it leaves the bat\n",
        "\n",
        "Intuitively, these should be relatedâ€”if you swing with a more upward bat path (higher attack angle), you're more likely to hit the ball upward (higher launch angle). Let's model their joint distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter to observations with BOTH attack_angle and launch_angle\n",
        "df_both = df.filter(pl.col('attack_angle').is_not_null())\n",
        "\n",
        "print(f\"Observations with both angles: {df_both.shape[0]}\")\n",
        "print(f\"Original dataset: {df.shape[0]}\")\n",
        "print(f\"Fraction with attack angle data: {df_both.shape[0]/df.shape[0]:.1%}\")\n",
        "\n",
        "# Stack into a (n_obs, 2) array\n",
        "angles = np.column_stack([\n",
        "    df_both['attack_angle'].to_numpy(),\n",
        "    df_both['launch_angle'].to_numpy()\n",
        "])\n",
        "\n",
        "print(f\"\\nData shape: {angles.shape}\")\n",
        "print(f\"Attack angle range: [{angles[:, 0].min():.1f}, {angles[:, 0].max():.1f}]\")\n",
        "print(f\"Launch angle range: [{angles[:, 1].min():.1f}, {angles[:, 1].max():.1f}]\")\n",
        "\n",
        "# Visualize the joint distribution\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=angles[:, 0],\n",
        "    y=angles[:, 1],\n",
        "    mode='markers',\n",
        "    marker=dict(size=3, opacity=0.3, color='steelblue'),\n",
        "    name='Observed'\n",
        "))\n",
        "fig.update_layout(\n",
        "    title='Joint Distribution of Attack Angle and Launch Angle',\n",
        "    xaxis_title='Attack Angle (degrees)',\n",
        "    yaxis_title='Launch Angle (degrees)',\n",
        "    width=600, height=500\n",
        ")\n",
        "fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There's a clear positive relationship! Higher attack angles tend to produce higher launch angles, though there's substantial scatter.\n",
        "\n",
        "### Building a Multivariate Normal Model\n",
        "\n",
        "A bivariate normal distribution is characterized by:\n",
        "- A **mean vector** $\\boldsymbol{\\mu} = [\\mu_{\\text{attack}}, \\mu_{\\text{launch}}]$\n",
        "- A **covariance matrix** $\\boldsymbol{\\Sigma}$ that captures variances and covariance:\n",
        "\n",
        "$$\\boldsymbol{\\Sigma} = \\begin{bmatrix}\n",
        "\\sigma_{\\text{attack}}^2 & \\rho \\sigma_{\\text{attack}} \\sigma_{\\text{launch}} \\\\\n",
        "\\rho \\sigma_{\\text{attack}} \\sigma_{\\text{launch}} & \\sigma_{\\text{launch}}^2\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "where $\\rho$ is the correlation coefficient.\n",
        "\n",
        "### The LKJ Prior for Correlation Matrices\n",
        "\n",
        "In PyMC, we'll use the **LKJ prior** for the correlation matrixâ€”a flexible prior distribution specifically designed for correlation matrices. The LKJ (Lewandowski-Kurowicka-Joe) prior is elegant because it's defined directly over valid correlation matrices, ensuring our model only considers mathematically valid values.\n",
        "\n",
        "The key parameter is **eta** ($\\eta$), which controls how much we favor correlations near zero:\n",
        "\n",
        "- **eta = 1**: Uniform distribution over all possible correlations (no preference for any particular correlation structure)\n",
        "- **eta > 1**: Increasingly favors correlations near zero (mild skepticism of strong correlations)\n",
        "- **eta < 1**: Favors extreme correlations near -1 or +1 (rarely used in practice)\n",
        "\n",
        "We'll use **eta = 2** as a mildly skeptical defaultâ€”we don't assume strong correlations between variables unless the data provides clear evidence. This acts as a form of regularization, preventing the model from overfitting to spurious correlations in small datasets.\n",
        "\n",
        "We'll also use coordinates to make the model readable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define coordinates\n",
        "COORDS = {\n",
        "    'variable': ['attack_angle', 'launch_angle'],\n",
        "    'obs': np.arange(angles.shape[0])\n",
        "}\n",
        "\n",
        "with pm.Model(coords=COORDS) as mvn_model:\n",
        "    # Mean vector (one mean per variable)\n",
        "    mu = pm.Normal('mu', mu=0, sigma=30, dims='variable')\n",
        "    \n",
        "    # Correlation matrix with LKJ prior (eta=2 is weakly informative)\n",
        "    # Standard deviations for each variable\n",
        "    chol, corr, stds = pm.LKJCholeskyCov(\n",
        "        'chol', n=2, eta=2.0, \n",
        "        sd_dist=pm.HalfNormal.dist(sigma=20, shape=2),\n",
        "        compute_corr=True\n",
        "    )\n",
        "    \n",
        "    # Multivariate normal likelihood\n",
        "    pm.MvNormal('angles', mu=mu, chol=chol,\n",
        "                      observed=angles, dims=('obs', 'variable'))\n",
        "    \n",
        "    # Sample\n",
        "    trace_mvn = pm.sample(500, tune=500, nuts_sampler='nutpie',\n",
        "                          random_seed=RNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine what we learned about the means, standard deviations, and correlation:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary table\n",
        "print(\"Posterior Summary:\")\n",
        "print(az.summary(trace_mvn, var_names=['mu', 'chol_stds', 'chol_corr']))\n",
        "\n",
        "# Visualize mean and standard deviation estimates\n",
        "az.plot_posterior(trace_mvn, var_names=['mu', 'chol_stds']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the correlation posterior using ArviZ\n",
        "az.plot_posterior(\n",
        "    trace_mvn, \n",
        "    var_names=['chol_corr'],\n",
        "    coords={'chol_corr_dim_0': 0, 'chol_corr_dim_1': 1}\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ArviZ's `plot_posterior` automatically computes and displays the posterior mean and credible interval for the correlation coefficient. The positive correlation confirms our intuition: attack angle and launch angle are positively related. When batters swing upward, they tend to hit the ball upward.\n",
        "\n",
        "Notice how we used the `coords` parameter to specify which element of the correlation matrix to visualizeâ€”this is where PyMC's coordinate system really shines, making it easy to extract and visualize specific components of multidimensional parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1.5: From Multivariate Normals to Gaussian Processes\n",
        "\n",
        "### Building Intuition: Functions as Infinite-Dimensional Vectors\n",
        "\n",
        "Here's the key insight that unlocks Gaussian processes: if you squint just right, a function is just a really long vectorâ€”infinitely long, in fact. At every point $x$ in the input space, the function has a value $f(x)$. You can think of $f$ as an infinite-dimensional vector, with one entry for each possible $x$.\n",
        "\n",
        "Now, you already know what a multivariate normal (MVN) distribution isâ€”it's a probability distribution over vectors. A Gaussian process is simply the natural extension of an MVN distribution to this infinite-dimensional case. It's a distribution over *functions*.\n",
        "\n",
        "The magic is that we can work with GPs using only finite-dimensional operations. We never actually deal with infinityâ€”we only care about the function values at the specific points where we have (or want) observations.\n",
        "\n",
        "### The Two Components of a GP\n",
        "\n",
        "A Gaussian process is completely specified by two functions:\n",
        "- A **mean function** $m(x)$ that gives the expected value at each point\n",
        "- A **covariance function** (or kernel) $k(x, x')$ that describes how function values at different points relate to each other\n",
        "\n",
        "We write: $f(x) \\sim \\mathcal{GP}(m(x), k(x, x'))$\n",
        "\n",
        "Think of it this way: the mean function tells you where the function is *centered*, while the covariance function tells you how *smooth* it is and how values at different locations are related. Together, they completely define a distribution over functions.\n",
        "\n",
        "In the next two sections, we'll explore each component in detailâ€”starting with covariance functions (Section 1.6), then mean functions (Section 1.7)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1.6: Covariance Functions\n",
        "\n",
        "### The Heart of Gaussian Processes\n",
        "\n",
        "If the mean function is where your prior belief lives, the covariance function (or kernel) is where the magic happens. The kernel defines the structure, smoothness, and patterns that your GP can express. Choosing the right kernel is often the most important modeling decision you'll make.\n",
        "\n",
        "A covariance function $k(x, x')$ must satisfy one critical property: it must produce **positive semi-definite covariance matrices** for any set of input points. This ensures that the resulting multivariate normal distributions are valid.\n",
        "\n",
        "Before we explore PyMC's built-in kernels, let's build intuition by implementing the squared exponential (ExpQuad) kernel ourselves and understanding how it works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ¤– EXERCISE: Implement the ExpQuad Kernel\n",
        "\n",
        "Let's start by implementing the exponential quadratic (RBF) kernel from scratch. This exercise will help you understand what a covariance function actually does.\n",
        "\n",
        "The ExpQuad kernel is defined as:\n",
        "\n",
        "$$k(x, x') = \\sigma^2 \\exp\\left(-\\frac{\\|x - x'\\|^2}{2\\ell^2}\\right)$$\n",
        "\n",
        "where $\\ell$ is the lengthscale (controls how quickly correlation decays with distance) and $\\sigma^2$ is the variance (controls overall scale of function values)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use your LLM to help complete this implementation\n",
        "\n",
        "# STEP 1: Ask your LLM to help you implement this function\n",
        "def exp_quad_kernel(X1, X2, lengthscale=1.0, variance=1.0):\n",
        "    \"\"\"\n",
        "    Compute the ExpQuad (RBF/Squared Exponential) covariance matrix.\n",
        "    \n",
        "    The ExpQuad kernel is: k(x, x') = variance * exp(-||x - x'||^2 / (2 * lengthscale^2))\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    X1 : array-like, shape (n_samples_1, n_features)\n",
        "        First input matrix\n",
        "    X2 : array-like, shape (n_samples_2, n_features)  \n",
        "        Second input matrix\n",
        "    lengthscale : float\n",
        "        Length scale parameter - controls how quickly correlation decays with distance\n",
        "    variance : float\n",
        "        Variance parameter - controls overall scale of function values\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    K : array, shape (n_samples_1, n_samples_2)\n",
        "        Covariance matrix\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "# STEP 2: Test your implementation\n",
        "# Create a simple test case\n",
        "X_test = np.array([[0.], [1.], [2.]])\n",
        "K_test = exp_quad_kernel(X_test, X_test, lengthscale=1.0, variance=1.0)\n",
        "\n",
        "print(\"Covariance matrix:\")\n",
        "print(K_test)\n",
        "print(\"\\nProperties to check:\")\n",
        "print(f\"1. Symmetric? {np.allclose(K_test, K_test.T)}\")\n",
        "print(f\"2. Diagonal values (should be ~{1.0}): {np.diag(K_test)}\")\n",
        "print(f\"3. Positive semi-definite? {np.all(np.linalg.eigvals(K_test) >= -1e-10)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Great! Let's verify the properties of our kernel:\n",
        "\n",
        "1. **Symmetric**: The covariance matrix is symmetric because $k(x, x') = k(x', x)$â€”the distance between two points doesn't depend on order\n",
        "2. **Diagonal = variance**: Points are perfectly correlated with themselves, so $k(x, x) = \\sigma^2 = 1.0$\n",
        "3. **Positive semi-definite**: All eigenvalues are non-negative, ensuring valid probability distributions\n",
        "\n",
        "Notice how off-diagonal values decay as points get farther apart. This decay rate is controlled by the lengthscale parameter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing the Kernel Structure\n",
        "\n",
        "Let's visualize this kernel as a heatmap to understand what it's doing. The kernel matrix tells us how correlated function values are at different input locations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a grid of points\n",
        "X_grid = np.linspace(0, 10, 50)[:, None]\n",
        "K_grid = exp_quad_kernel(X_grid, X_grid, lengthscale=1.5, variance=1.0)\n",
        "\n",
        "# Visualize the covariance matrix\n",
        "fig = px.imshow(K_grid, \n",
        "                x=X_grid.flatten(),\n",
        "                y=X_grid.flatten(),\n",
        "                color_continuous_scale='Viridis',\n",
        "                labels=dict(x=\"x\", y=\"x'\", color=\"Covariance\"),\n",
        "                title=\"ExpQuad Kernel: How function values covary\")\n",
        "fig.update_layout(width=600, height=500)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice the structure: the diagonal is bright (variance = 1.0), meaning each point is perfectly correlated with itself. As you move away from the diagonal, the correlation decays smoothly. This decay rate is controlled by the lengthscale parameterâ€”it determines how far apart two points can be before they become essentially uncorrelated.\n",
        "\n",
        "The symmetry around the diagonal confirms that our kernel treats distance symmetrically: the correlation between $x=2$ and $x=5$ is the same as between $x=5$ and $x=2$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### From Covariance Matrix to Functions\n",
        "\n",
        "Now comes the beautiful connection: we can use this kernel to draw actual functions from a GP prior. Remember, we're just sampling from a multivariate normal distribution!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define input points where we want to evaluate the function\n",
        "X = np.linspace(0, 10, 100)[:, None]\n",
        "\n",
        "# Build the covariance matrix\n",
        "lengthscale = 1.5\n",
        "variance = 1.0\n",
        "K = exp_quad_kernel(X, X, lengthscale=lengthscale, variance=variance)\n",
        "\n",
        "# Add small jitter for numerical stability\n",
        "K += 1e-8 * np.eye(len(X))\n",
        "\n",
        "# Zero mean function\n",
        "mean = np.zeros(len(X))\n",
        "\n",
        "# Draw sample functions from the GP prior\n",
        "n_samples = 5\n",
        "f_samples = RNG.multivariate_normal(mean, K, size=n_samples)\n",
        "\n",
        "fig = go.Figure()\n",
        "for i in range(n_samples):\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=X.flatten(),\n",
        "        y=f_samples[i],\n",
        "        mode='lines',\n",
        "        name=f'Sample {i+1}',\n",
        "        line=dict(width=2),\n",
        "        opacity=0.7\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=f'Functions Drawn from GP Prior (lengthscale={lengthscale}, variance={variance})',\n",
        "    xaxis_title='x',\n",
        "    yaxis_title='f(x)',\n",
        "    showlegend=True\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These are functions drawn from our GP prior! Each colored line represents one possible function that the GP considers plausible before seeing any data. Notice how smooth they areâ€”that smoothness comes from the ExpQuad kernel.\n",
        "\n",
        "Here's the beautiful thing: we just drew these functions by sampling from a multivariate normal distribution. The connection is direct:\n",
        "- The **mean vector** of the MVN is our mean function evaluated at our input points (zero in this case)\n",
        "- The **covariance matrix** of the MVN is our kernel evaluated at all pairs of input points\n",
        "\n",
        "This is the heart of Gaussian processes: a GP is just an MVN distribution over function values, with the structure determined by the covariance function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding Lengthscale: The Smoothness Dial\n",
        "\n",
        "The lengthscale parameter is often the most important hyperparameter in a GP model. It controls how quickly the correlation between function values decays as you move apart in input space. Let's visualize its effect:\n",
        "\n",
        "- **Small lengthscale** (0.5): Function values decorrelate quickly â†’ wiggly, rapidly varying functions\n",
        "- **Medium lengthscale** (1.5): Moderate correlation decay â†’ smooth but responsive\n",
        "- **Large lengthscale** (3.0): Function values stay correlated over long distances â†’ very smooth, slowly varying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lengthscales = [0.5, 1.5, 3.0]\n",
        "\n",
        "fig = make_subplots(rows=1, cols=3,\n",
        "                    subplot_titles=[f'lengthscale = {l}' for l in lengthscales])\n",
        "\n",
        "for idx, ls in enumerate(lengthscales, 1):\n",
        "    K = exp_quad_kernel(X, X, lengthscale=ls, variance=1.0)\n",
        "    K += 1e-8 * np.eye(len(X))\n",
        "    \n",
        "    samples = RNG.multivariate_normal(np.zeros(len(X)), K, size=3)\n",
        "    \n",
        "    for sample in samples:\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=X.flatten(), y=sample, mode='lines',\n",
        "                      showlegend=False, line=dict(width=1.5)),\n",
        "            row=1, col=idx\n",
        "        )\n",
        "\n",
        "fig.update_xaxes(title_text=\"x\")\n",
        "fig.update_yaxes(title_text=\"f(x)\", col=1)\n",
        "fig.update_layout(height=300, width=900,\n",
        "                  title_text=\"Effect of Lengthscale on Function Smoothness\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With lengthscale = 0.5, the functions are highly wigglyâ€”they can change direction rapidly. With lengthscale = 3.0, the functions are very smooth and change slowly across the entire domain.\n",
        "\n",
        "This parameter directly encodes your prior belief about how smooth the underlying function should be. If you're modeling temperature over a day, you might use a larger lengthscale (temperature changes gradually). If you're modeling stock prices, you might need a smaller lengthscale (prices can change rapidly).\n",
        "\n",
        "The key insight: **lengthscale sets the spatial scale at which the function varies**. It's like setting the \"resolution\" of patterns the GP can capture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding Variance: The Amplitude Dial\n",
        "\n",
        "While lengthscale controls how smooth functions are, the variance parameter $\\sigma^2$ controls their **amplitude**â€”how far function values can deviate from the mean. Think of it as a volume knob: it scales the magnitude of variations without changing the correlation structure or smoothness.\n",
        "\n",
        "The variance parameter appears in the kernel as a multiplicative factor. For the ExpQuad kernel:\n",
        "\n",
        "$$k(x, x') = \\sigma^2 \\exp\\left(-\\frac{\\|x - x'\\|^2}{2\\ell^2}\\right)$$\n",
        "\n",
        "Notice that $\\sigma^2$ multiplies the entire exponential term, scaling all covariances uniformly. Let's visualize how different variance values affect the functions we can draw from a GP prior:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variances = [0.2, 1.0, 3.0]\n",
        "\n",
        "fig = make_subplots(rows=1, cols=3,\n",
        "                    subplot_titles=[f'variance = {v}' for v in variances])\n",
        "\n",
        "for idx, var in enumerate(variances, 1):\n",
        "    K = exp_quad_kernel(X, X, lengthscale=1.5, variance=var)\n",
        "    K += 1e-8 * np.eye(len(X))\n",
        "\n",
        "    samples = RNG.multivariate_normal(np.zeros(len(X)), K, size=3)\n",
        "\n",
        "    for sample in samples:\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=X.flatten(), y=sample, mode='lines',\n",
        "                      showlegend=False, line=dict(width=1.5)),\n",
        "            row=1, col=idx\n",
        "        )\n",
        "\n",
        "# Use consistent y-axis scale to emphasize amplitude differences\n",
        "fig.update_xaxes(title_text=\"x\")\n",
        "fig.update_yaxes(title_text=\"f(x)\", col=1, range=[-6, 6])\n",
        "fig.update_yaxes(range=[-6, 6], col=2)\n",
        "fig.update_yaxes(range=[-6, 6], col=3)\n",
        "fig.update_layout(height=300, width=900,\n",
        "                  title_text=\"Effect of Variance on Function Amplitude\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The visualization shows how variance scales the amplitude while preserving smoothness. Notice that the functions wiggle at the same spatial frequency across all three panelsâ€”that's because lengthscale is constant at 1.5. What changes is the **magnitude of the wiggles**:\n",
        "\n",
        "- With variance = 0.2, functions hover close to zero, rarely venturing beyond Â±1\n",
        "- With variance = 1.0, functions explore a moderate range around Â±2  \n",
        "- With variance = 3.0, functions make large excursions, easily reaching Â±4 or more\n",
        "\n",
        "In practical applications, if your data have a particular scale (e.g., temperatures ranging from 10-30Â°C), the variance should reflect that scale. Standardizing your data often simplifies prior specification by making variance = 1.0 a sensible default."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lengthscale vs Variance: Independent Controls\n",
        "\n",
        "These two parameters work together but control orthogonal aspects of the GP:\n",
        "- **Lengthscale** ($\\ell$): Controls the **spatial scale** of variation (smoothness, correlation range)\n",
        "- **Variance** ($\\sigma^2$): Controls the **amplitude** of variation (how far from the mean)\n",
        "\n",
        "You can have smooth high-amplitude functions (large lengthscale, large variance), wiggly low-amplitude functions (small lengthscale, small variance), or any combination. This flexibility is part of what makes GPs so powerfulâ€”you can tune smoothness and amplitude independently to match your domain knowledge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Working with PyMC's Kernel API\n",
        "\n",
        "Now that we understand kernels deeply, let's use PyMC's built-in implementations. They're faster, more numerically stable, and integrate seamlessly with PyMC's computational backend. Let's create a helper function to visualize any PyMC kernel:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_kernel(cov_func, X, title, n_samples=3):\n",
        "    \"\"\"Visualize kernel covariance matrix and sample functions.\"\"\"\n",
        "    K = cov_func(X).eval()\n",
        "    K += 1e-6 * np.eye(len(X))\n",
        "\n",
        "    fig = make_subplots(rows=1, cols=2, \n",
        "                        subplot_titles=['Sample Functions', 'Covariance Matrix'],\n",
        "                        specs=[[{'type': 'scatter'}, {'type': 'heatmap'}]],\n",
        "                        horizontal_spacing=0.15)\n",
        "\n",
        "    # Draw sample functions\n",
        "    samples = RNG.multivariate_normal(np.zeros(len(X)), K, size=n_samples)\n",
        "    for sample in samples:\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=X.flatten(), y=sample, mode='lines', \n",
        "                      showlegend=False, line=dict(width=1.5)), \n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "    # Show covariance matrix\n",
        "    fig.add_trace(\n",
        "        go.Heatmap(z=K, colorscale='Viridis', showscale=True,\n",
        "                   colorbar=dict(x=1.0, len=0.75)), \n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "    fig.update_xaxes(title_text=\"x\", row=1, col=1)\n",
        "    fig.update_yaxes(title_text=\"f(x)\", row=1, col=1)\n",
        "    fig.update_xaxes(title_text=\"Index\", row=1, col=2)\n",
        "    fig.update_yaxes(title_text=\"Index\", row=1, col=2)\n",
        "    fig.update_layout(height=350, width=900, title_text=title)\n",
        "    return fig\n",
        "\n",
        "# Define a grid of points for visualization\n",
        "X_kern = np.linspace(0, 10, 80)[:, None]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PyMC's ExpQuad Kernel\n",
        "\n",
        "Now let's use our helper function to visualize PyMC's built-in ExpQuad kernel. Notice how we specify `input_dim=1` (for 1D inputs) and `ls=1.5` (lengthscale):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cov_expquad = pm.gp.cov.ExpQuad(input_dim=1, ls=1.5)\n",
        "fig = visualize_kernel(cov_expquad, X_kern, \"PyMC ExpQuad Kernel (lengthscale=1.5)\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The covariance matrix shows the smooth decay we expect, and the sample functions are appropriately smooth. PyMC's implementation matches our manual implementation but is optimized for performance and numerical stability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1.7: Mean Functions\n",
        "\n",
        "### The Role of the Mean Function\n",
        "\n",
        "So far, we've been using a zero mean function, but this is just one choice among many. The mean function $m(x)$ specifies the expected value of the function at each input point, before we see any data. Think of it as your baseline assumption about what the function looks like.\n",
        "\n",
        "The mean function shifts functions up or down (or even gives them a trend), but it doesn't affect their smoothness or correlation structureâ€”that's the job of the covariance function. In many applications, we stick with a zero mean because:\n",
        "\n",
        "1. **Simplicity**: It introduces no additional parameters\n",
        "2. **Flexibility**: The covariance function is usually flexible enough to capture the important structure\n",
        "3. **Standardization**: If we're working with mean-centered data, a zero mean function makes sense\n",
        "\n",
        "However, when you have strong prior knowledge about the general shape of your functionâ€”maybe you know it should have a linear trend or oscillate around some valueâ€”encoding this in the mean function can improve your model.\n",
        "\n",
        "Let's explore the three most common mean functions: zero, constant, and linear."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Different Mean Functions\n",
        "\n",
        "Let's see how different mean functions affect the GP prior. We'll use the same ExpQuad covariance function but vary the mean:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define three mean functions\n",
        "X_mean = np.linspace(0, 10, 100)[:, None]\n",
        "mean_zero = np.zeros(len(X_mean))\n",
        "mean_const = np.full(len(X_mean), 5.0)\n",
        "mean_linear = 0.5 * X_mean.flatten() + 2.0\n",
        "\n",
        "# Use the same covariance for all\n",
        "K_mean = exp_quad_kernel(X_mean, X_mean, lengthscale=1.5, variance=1.0)\n",
        "K_mean += 1e-8 * np.eye(len(X_mean))\n",
        "\n",
        "# Create subplots\n",
        "fig = make_subplots(rows=1, cols=3,\n",
        "                    subplot_titles=['Zero Mean', 'Constant Mean (5.0)', 'Linear Mean (0.5x + 2)'])\n",
        "\n",
        "means = [mean_zero, mean_const, mean_linear]\n",
        "for idx, mean_func in enumerate(means, 1):\n",
        "    # Draw samples from GP with this mean\n",
        "    samples = RNG.multivariate_normal(mean_func, K_mean, size=3)\n",
        "    \n",
        "    # Plot samples\n",
        "    for sample in samples:\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=X_mean.flatten(), y=sample, mode='lines',\n",
        "                      showlegend=False, line=dict(width=1.5),\n",
        "                      opacity=0.7),\n",
        "            row=1, col=idx\n",
        "        )\n",
        "    \n",
        "    # Plot mean function\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=X_mean.flatten(), y=mean_func, mode='lines',\n",
        "                  showlegend=False, line=dict(color='black', width=2, dash='dash')),\n",
        "        row=1, col=idx\n",
        "    )\n",
        "\n",
        "fig.update_xaxes(title_text=\"x\")\n",
        "fig.update_yaxes(title_text=\"f(x)\", col=1)\n",
        "fig.update_layout(height=350, width=1000,\n",
        "                  title_text=\"Effect of Mean Function on GP Prior\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice how the mean function (black dashed line) acts as an \"anchor\" around which the random functions vary:\n",
        "\n",
        "- **Zero mean** (left): Functions wander around zero, with equal probability of being positive or negative\n",
        "- **Constant mean** (middle): Functions are shifted up to fluctuate around 5.0, but remain roughly constant on average\n",
        "- **Linear mean** (right): Functions inherit the upward trend, but with wiggles around that trend\n",
        "\n",
        "The key insight: the covariance function determines the smoothness and correlation structure (how wiggly the functions are), while the mean function determines where they're centered or whether they have a systematic trend. They work together, but control different aspects of the prior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PyMC's Mean Function API\n",
        "\n",
        "PyMC provides convenient classes for common mean functions. Let's see how they work:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create mean function objects\n",
        "mean_zero_pymc = pm.gp.mean.Zero()  # Default\n",
        "mean_const_pymc = pm.gp.mean.Constant(c=5.0)\n",
        "mean_linear_pymc = pm.gp.mean.Linear(coeffs=0.5, intercept=2.0)\n",
        "\n",
        "# Test them on a few points\n",
        "X_test_mean = np.array([[0.], [5.], [10.]])\n",
        "print(\"Zero mean:\", mean_zero_pymc(X_test_mean).eval())\n",
        "print(\"Constant mean:\", mean_const_pymc(X_test_mean).eval())\n",
        "print(\"Linear mean:\", mean_linear_pymc(X_test_mean).eval())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PyMC's mean functions integrate seamlessly with GP models. When building a GP, you can pass a mean function like this:\n",
        "\n",
        "```python\n",
        "cov = pm.gp.cov.ExpQuad(input_dim=1, ls=1.5)\n",
        "mean = pm.gp.mean.Linear(coeffs=0.5, intercept=0.0)\n",
        "gp = pm.gp.Marginal(mean_func=mean, cov_func=cov)\n",
        "```\n",
        "\n",
        "### When to Use Each Mean Function\n",
        "\n",
        "Here's a practical guide:\n",
        "\n",
        "- **Zero mean**: Default choice, especially with standardized data or when you have no strong prior beliefs\n",
        "- **Constant mean**: When you expect the function to fluctuate around some non-zero value (e.g., temperature anomalies around a baseline)\n",
        "- **Linear mean**: When you have a clear trend in your data and want the GP to model deviations from that trend\n",
        "\n",
        "Just remember: **the mean function doesn't change the \"wiggliness\" or correlation structure**â€”that's entirely determined by the covariance function. The mean function simply shifts or tilts the family of functions we're considering.\n",
        "\n",
        "In practice, most GP applications use a zero or constant mean function, letting the flexible covariance function do the heavy lifting. The covariance function is where the real magic happens!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Why the Mean Function Matters Less Than You Think\n",
        "\n",
        "Here's a critical insight: once you have data, the mean function's influence largely disappears **in regions where you have observations**. It only matters in regions without data. Let's see why with a quick example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "line": {
                    "color": "gray",
                    "dash": "dash"
                  },
                  "mode": "lines",
                  "name": "Prior: zero mean",
                  "type": "scatter",
                  "x": {
                    "bdata": "AAAAAAAAAAAxb2dIzNu5PzFvZ0jM28k/ZZNNNtlk0z8xb2dIzNvZP3+lQK1fKeA/ZZNNNtlk4z9LgVq/UqDmPzFvZ0jM2+k/F1100UUX7T9/pUCtXynwP3Icx3Ecx/E/ZZNNNtlk8z9YCtT6lQL1P0uBWr9SoPY/Pvjggw8++D8xb2dIzNv5PyTm7QyJefs/F1100UUX/T8K1PqVArX+P3+lQK1fKQBA+OCDDz74AEByHMdxHMcBQOtXCtT6lQJAZZNNNtlkA0DezpCYtzMEQFgK1PqVAgVA0UUXXXTRBUBLgVq/UqAGQMS8nSExbwdAPvjggw8+CEC3MyTm7QwJQDFvZ0jM2wlAq6qqqqqqCkAk5u0MiXkLQJ4hMW9nSAxAF1100UUXDUCRmLczJOYNQArU+pUCtQ5AhA8++OCDD0B/pUCtXykQQDtDYt7OkBBA+OCDDz74EEC1fqVArV8RQHIcx3EcxxFALrrooosuEkDrVwrU+pUSQKj1KwVq/RJAZZNNNtlkE0AiMW9nSMwTQN7OkJi3MxRAm2yyySabFEBYCtT6lQIVQBWo9SsFahVA0UUXXXTRFUCO4ziO4zgWQEuBWr9SoBZACB988MEHF0DEvJ0hMW8XQIFav1Kg1hdAPvjggw8+GED7lQK1fqUYQLczJObtDBlAdNFFF110GUAxb2dIzNsZQO4MiXk7QxpAq6qqqqqqGkBnSMzbGRIbQCTm7QyJeRtA4YMPPvjgG0CeITFvZ0gcQFq/UqDWrxxAF1100UUXHUDU+pUCtX4dQJGYtzMk5h1ATTbZZJNNHkAK1PqVArUeQMdxHMdxHB9AhA8++OCDH0BArV8pUOsfQH+lQK1fKSBAXXTRRRddIEA7Q2LezpAgQBoS83aGxCBA+OCDDz74IEDXrxSo9SshQLV+pUCtXyFAk0022WSTIUByHMdxHMchQFDrVwrU+iFALrrooosuIkANiXk7Q2IiQOtXCtT6lSJAyiabbLLJIkCo9SsFav0iQIbEvJ0hMSNAZZNNNtlkI0BDYt7OkJgjQCIxb2dIzCNAAAAAAAAAJEA=",
                    "dtype": "f8"
                  },
                  "y": {
                    "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=",
                    "dtype": "f8"
                  }
                },
                {
                  "line": {
                    "color": "lightblue",
                    "dash": "dash"
                  },
                  "mode": "lines",
                  "name": "Prior: constant mean (3.0)",
                  "type": "scatter",
                  "x": {
                    "bdata": "AAAAAAAAAAAxb2dIzNu5PzFvZ0jM28k/ZZNNNtlk0z8xb2dIzNvZP3+lQK1fKeA/ZZNNNtlk4z9LgVq/UqDmPzFvZ0jM2+k/F1100UUX7T9/pUCtXynwP3Icx3Ecx/E/ZZNNNtlk8z9YCtT6lQL1P0uBWr9SoPY/Pvjggw8++D8xb2dIzNv5PyTm7QyJefs/F1100UUX/T8K1PqVArX+P3+lQK1fKQBA+OCDDz74AEByHMdxHMcBQOtXCtT6lQJAZZNNNtlkA0DezpCYtzMEQFgK1PqVAgVA0UUXXXTRBUBLgVq/UqAGQMS8nSExbwdAPvjggw8+CEC3MyTm7QwJQDFvZ0jM2wlAq6qqqqqqCkAk5u0MiXkLQJ4hMW9nSAxAF1100UUXDUCRmLczJOYNQArU+pUCtQ5AhA8++OCDD0B/pUCtXykQQDtDYt7OkBBA+OCDDz74EEC1fqVArV8RQHIcx3EcxxFALrrooosuEkDrVwrU+pUSQKj1KwVq/RJAZZNNNtlkE0AiMW9nSMwTQN7OkJi3MxRAm2yyySabFEBYCtT6lQIVQBWo9SsFahVA0UUXXXTRFUCO4ziO4zgWQEuBWr9SoBZACB988MEHF0DEvJ0hMW8XQIFav1Kg1hdAPvjggw8+GED7lQK1fqUYQLczJObtDBlAdNFFF110GUAxb2dIzNsZQO4MiXk7QxpAq6qqqqqqGkBnSMzbGRIbQCTm7QyJeRtA4YMPPvjgG0CeITFvZ0gcQFq/UqDWrxxAF1100UUXHUDU+pUCtX4dQJGYtzMk5h1ATTbZZJNNHkAK1PqVArUeQMdxHMdxHB9AhA8++OCDH0BArV8pUOsfQH+lQK1fKSBAXXTRRRddIEA7Q2LezpAgQBoS83aGxCBA+OCDDz74IEDXrxSo9SshQLV+pUCtXyFAk0022WSTIUByHMdxHMchQFDrVwrU+iFALrrooosuIkANiXk7Q2IiQOtXCtT6lSJAyiabbLLJIkCo9SsFav0iQIbEvJ0hMSNAZZNNNtlkI0BDYt7OkJgjQCIxb2dIzCNAAAAAAAAAJEA=",
                    "dtype": "f8"
                  },
                  "y": {
                    "bdata": "AAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEAAAAAAAAAIQAAAAAAAAAhAAAAAAAAACEA=",
                    "dtype": "f8"
                  }
                },
                {
                  "line": {
                    "color": "darkblue",
                    "width": 2
                  },
                  "mode": "lines",
                  "name": "Posterior: zero mean",
                  "type": "scatter",
                  "x": {
                    "bdata": "AAAAAAAAAAAxb2dIzNu5PzFvZ0jM28k/ZZNNNtlk0z8xb2dIzNvZP3+lQK1fKeA/ZZNNNtlk4z9LgVq/UqDmPzFvZ0jM2+k/F1100UUX7T9/pUCtXynwP3Icx3Ecx/E/ZZNNNtlk8z9YCtT6lQL1P0uBWr9SoPY/Pvjggw8++D8xb2dIzNv5PyTm7QyJefs/F1100UUX/T8K1PqVArX+P3+lQK1fKQBA+OCDDz74AEByHMdxHMcBQOtXCtT6lQJAZZNNNtlkA0DezpCYtzMEQFgK1PqVAgVA0UUXXXTRBUBLgVq/UqAGQMS8nSExbwdAPvjggw8+CEC3MyTm7QwJQDFvZ0jM2wlAq6qqqqqqCkAk5u0MiXkLQJ4hMW9nSAxAF1100UUXDUCRmLczJOYNQArU+pUCtQ5AhA8++OCDD0B/pUCtXykQQDtDYt7OkBBA+OCDDz74EEC1fqVArV8RQHIcx3EcxxFALrrooosuEkDrVwrU+pUSQKj1KwVq/RJAZZNNNtlkE0AiMW9nSMwTQN7OkJi3MxRAm2yyySabFEBYCtT6lQIVQBWo9SsFahVA0UUXXXTRFUCO4ziO4zgWQEuBWr9SoBZACB988MEHF0DEvJ0hMW8XQIFav1Kg1hdAPvjggw8+GED7lQK1fqUYQLczJObtDBlAdNFFF110GUAxb2dIzNsZQO4MiXk7QxpAq6qqqqqqGkBnSMzbGRIbQCTm7QyJeRtA4YMPPvjgG0CeITFvZ0gcQFq/UqDWrxxAF1100UUXHUDU+pUCtX4dQJGYtzMk5h1ATTbZZJNNHkAK1PqVArUeQMdxHMdxHB9AhA8++OCDH0BArV8pUOsfQH+lQK1fKSBAXXTRRRddIEA7Q2LezpAgQBoS83aGxCBA+OCDDz74IEDXrxSo9SshQLV+pUCtXyFAk0022WSTIUByHMdxHMchQFDrVwrU+iFALrrooosuIkANiXk7Q2IiQOtXCtT6lSJAyiabbLLJIkCo9SsFav0iQIbEvJ0hMSNAZZNNNtlkI0BDYt7OkJgjQCIxb2dIzCNAAAAAAAAAJEA=",
                    "dtype": "f8"
                  },
                  "y": {
                    "bdata": "cioh7QF/wD9i0ShH+xbEPzR0qVkFOMg/rNARV8fmzD9vwbstFhLRP3/5L2pT9tM/wSqKqcgb1z8pfbdhXnvaP6UV3KMdC94/n1/QMR3f4D9M3F2io8LiP1Sa04hKp+Q/vY9mdV6D5j+vtjJtqEzoP5j5qYjV+Ok/s4AufOh96z+G/NVlrtLsP/UOSngv7+0/DJ7y6xPN7j8Q6msU9mfvP3bIGJCbve8/JoDRMBHO7z+QyrlVp5vvP/tkr8jOKu8/Qt62ltiB7j8VNu+QnajtP1DQKvUTqOw/anUb/tqJ6z/+YCOtxFfqP4cv/PZlG+k/lmHknrTd5z+uJiySuKbmP0BYIKdUfeU/Ajp8cChn5D90lQmZimjjPypqxyiZhOI/TKq5Xlu94T86QrGW7xPhP6o+LRm/iOA/kOtHvbEb4D8+I1PTt5jfP87EHVZFNN8/vi5mRKYI3z84dNuYWBTfPw6Hx+S3Vd8/TCHhTuLK3z8lS00QyDjgP9MaGH5zo+A/66YfNqkj4T+bXZt2NbfhP+OfWHN5W+I/MBxJOHcN4z/hPjy868njP3w68x52jeQ/HrTnQ8lU5T9Pg1Zo4xzmP5d+aCVG4+Y/Ri8frCim5z8i9ccInmToP7JmPeipHuk/x7bqqT/V6T+ozMJkKYrqP69xDsLWP+s/1P3q+RX56z8AzC6Wu7jsP0TAe6s/ge0/ruXdvFhU7j/JOsROnTLvP7IRgJaaDfA/xUOlRdGF8D+RJme+1P/wP9idbfOsePE/yK2MoJ7s8T9C4/g1U1fyPwyGmXYPtPI/MDDsIfX98j9/XpP/SjDzP45zogbGRvM/8+8hNM498z8WDpr2uRLzP8EyMdf7w/I/R+OUKD9R8j+cNCLkcbvxP8ONkVy7BPE/rE/M5mAw8D9qldbWNYXuP9jw2cG7gOw/sRLBxjZe6j/OD6Xe/yjoPyUUv2Vj7OU/akGb9Ciz4z8PlJENLIfhP0QO4dIU4t4/Wh5pVNXv2j8+AYtuuELXP9HgdWGe4tM/PuBTw0PU0D/sdsjt/zLMP7ggDd48Y8c/gWGsAJMzwz8=",
                    "dtype": "f8"
                  }
                },
                {
                  "line": {
                    "color": "darkred",
                    "width": 2
                  },
                  "mode": "lines",
                  "name": "Posterior: constant mean",
                  "type": "scatter",
                  "x": {
                    "bdata": "AAAAAAAAAAAxb2dIzNu5PzFvZ0jM28k/ZZNNNtlk0z8xb2dIzNvZP3+lQK1fKeA/ZZNNNtlk4z9LgVq/UqDmPzFvZ0jM2+k/F1100UUX7T9/pUCtXynwP3Icx3Ecx/E/ZZNNNtlk8z9YCtT6lQL1P0uBWr9SoPY/Pvjggw8++D8xb2dIzNv5PyTm7QyJefs/F1100UUX/T8K1PqVArX+P3+lQK1fKQBA+OCDDz74AEByHMdxHMcBQOtXCtT6lQJAZZNNNtlkA0DezpCYtzMEQFgK1PqVAgVA0UUXXXTRBUBLgVq/UqAGQMS8nSExbwdAPvjggw8+CEC3MyTm7QwJQDFvZ0jM2wlAq6qqqqqqCkAk5u0MiXkLQJ4hMW9nSAxAF1100UUXDUCRmLczJOYNQArU+pUCtQ5AhA8++OCDD0B/pUCtXykQQDtDYt7OkBBA+OCDDz74EEC1fqVArV8RQHIcx3EcxxFALrrooosuEkDrVwrU+pUSQKj1KwVq/RJAZZNNNtlkE0AiMW9nSMwTQN7OkJi3MxRAm2yyySabFEBYCtT6lQIVQBWo9SsFahVA0UUXXXTRFUCO4ziO4zgWQEuBWr9SoBZACB988MEHF0DEvJ0hMW8XQIFav1Kg1hdAPvjggw8+GED7lQK1fqUYQLczJObtDBlAdNFFF110GUAxb2dIzNsZQO4MiXk7QxpAq6qqqqqqGkBnSMzbGRIbQCTm7QyJeRtA4YMPPvjgG0CeITFvZ0gcQFq/UqDWrxxAF1100UUXHUDU+pUCtX4dQJGYtzMk5h1ATTbZZJNNHkAK1PqVArUeQMdxHMdxHB9AhA8++OCDH0BArV8pUOsfQH+lQK1fKSBAXXTRRRddIEA7Q2LezpAgQBoS83aGxCBA+OCDDz74IEDXrxSo9SshQLV+pUCtXyFAk0022WSTIUByHMdxHMchQFDrVwrU+iFALrrooosuIkANiXk7Q2IiQOtXCtT6lSJAyiabbLLJIkCo9SsFav0iQIbEvJ0hMSNAZZNNNtlkI0BDYt7OkJgjQCIxb2dIzCNAAAAAAAAAJEA=",
                    "dtype": "f8"
                  },
                  "y": {
                    "bdata": "ezBKhd8kBkAlrUQOFr0FQG/nksGvRQVA4VjcOBC+BEANBqDL/iUEQMIan725fQNA1+Nm0AXGAkBFCLF0OAACQDermfY6LgFAIg2zSoVSAEDrb6I0H+D+P0T5Qp10FP0/m/kqNVpJ+z/8v1qpXIb5P4YcFoHp0vc/I0yVP+019j/+UdnYcrX0P6FYrtNLVvM/j4Wzasgb8j+YVIpIhgfxP+ATChlbGfA/TL+LW7ye7j9Eq/EIJEztP9R4rJxXMew/sGZ1zehC6z94jIRzd3TqPwQpiWGruek/OP3nFS0H6T8AQAx1iFPoP6wZ/wnml+c/OLJGc4rQ5j98AuFqEP3lPziNa9hXIOU/JAWyCCtA5D8YmvDcoWTjP9iKkt9Ql+I/8BQdEVfi4T+0h/1uYE/hP0R2Flm05uA/iEH+7mWu4D90ce5WuangP0B1UejL2OA/HJ+M44Y44T/4cRNU3cLhP/jYhKBOb+I/cK/r16Az4z9IE4ucwATkP9CD2SSx1+Q/KFgUfnWi5T9EbSMn3VzmP4yv4CMhAec/cM09gEOM5z/gp/1iKf7nP5wCMatuWeg/6NJi9Pii6D/AmHcWVuHoP3A2Di33G+k/ALd4bVxa6T/4hwpGR6PpP4BGglUH/Ok/vAyh2/Nn6j88BKykHujqPyi3WppHe+s/eGhOrBEe7D+s7PlMc8vsP+DEYu9Wfe0/zLATVVst7j+8bw+AoNXuPzD/tAWNce8/KNisX3j+7z+im+jHFD7wP1gNYteOdvA/rvFyrEer8D+bDyjsHuDwPz4x5Gf8GfE/aHRLPX1e8T9s6JFpj7PxP+hjPmAEH/I/hQ9/ySOm8j+6vZdHR03zP1GShRWHF/Q/zxlPnX0G9T+/hav7JRr2P37hfwLXUPc/cVtK6Fmn+D9zaiyoGRn6PxJdrlNmoPs/DzvYXcY2/T8EtCtIT9X+P+qFKYt/OgBAksVlO4gHAUCGjYJFos4BQGc61kIPjQJATMLCZYdAA0C6eypeRucDQPdJF9IPgARA37fVOywKBUCa19RqX4UFQBzysifa8QVA7OOClihQBkA=",
                    "dtype": "f8"
                  }
                },
                {
                  "marker": {
                    "color": "red",
                    "size": 10,
                    "symbol": "x"
                  },
                  "mode": "markers",
                  "name": "Observed data",
                  "type": "scatter",
                  "x": {
                    "bdata": "AAAAAAAAAEAAAAAAAAAQQAAAAAAAABhAAAAAAAAAIEA=",
                    "dtype": "f8"
                  },
                  "y": {
                    "bdata": "AAAAAAAA8D8AAAAAAADgP5qZmZmZmek/MzMzMzMz8z8=",
                    "dtype": "f8"
                  }
                }
              ],
              "layout": {
                "height": 400,
                "shapes": [
                  {
                    "fillcolor": "lightyellow",
                    "layer": "below",
                    "line": {
                      "width": 0
                    },
                    "opacity": 0.3,
                    "type": "rect",
                    "x0": 0,
                    "x1": 2,
                    "xref": "x",
                    "y0": 0,
                    "y1": 1,
                    "yref": "y domain"
                  },
                  {
                    "fillcolor": "lightyellow",
                    "layer": "below",
                    "line": {
                      "width": 0
                    },
                    "opacity": 0.3,
                    "type": "rect",
                    "x0": 8,
                    "x1": 10,
                    "xref": "x",
                    "y0": 0,
                    "y1": 1,
                    "yref": "y domain"
                  }
                ],
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "white",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "white",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "#C8D4E3",
                          "linecolor": "#C8D4E3",
                          "minorgridcolor": "#C8D4E3",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "#C8D4E3",
                          "linecolor": "#C8D4E3",
                          "minorgridcolor": "#C8D4E3",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermap": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermap"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "white",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "#C8D4E3"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "white",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "#EBF0F8",
                        "linecolor": "#EBF0F8",
                        "ticks": ""
                      },
                      "bgcolor": "white",
                      "radialaxis": {
                        "gridcolor": "#EBF0F8",
                        "linecolor": "#EBF0F8",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "white",
                        "gridcolor": "#DFE8F3",
                        "gridwidth": 2,
                        "linecolor": "#EBF0F8",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "#EBF0F8"
                      },
                      "yaxis": {
                        "backgroundcolor": "white",
                        "gridcolor": "#DFE8F3",
                        "gridwidth": 2,
                        "linecolor": "#EBF0F8",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "#EBF0F8"
                      },
                      "zaxis": {
                        "backgroundcolor": "white",
                        "gridcolor": "#DFE8F3",
                        "gridwidth": 2,
                        "linecolor": "#EBF0F8",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "#EBF0F8"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "#DFE8F3",
                        "linecolor": "#A2B1C6",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "#DFE8F3",
                        "linecolor": "#A2B1C6",
                        "ticks": ""
                      },
                      "bgcolor": "white",
                      "caxis": {
                        "gridcolor": "#DFE8F3",
                        "linecolor": "#A2B1C6",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "#EBF0F8",
                      "linecolor": "#EBF0F8",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "#EBF0F8",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "#EBF0F8",
                      "linecolor": "#EBF0F8",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "#EBF0F8",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Mean Function Influence: Only Matters Without Data"
                },
                "xaxis": {
                  "title": {
                    "text": "x"
                  }
                },
                "yaxis": {
                  "title": {
                    "text": "f(x)"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Generate some observations\n",
        "X_obs = np.array([[2.], [4.], [6.], [8.]])  \n",
        "y_obs = np.array([1.0, 0.5, 0.8, 1.2])\n",
        "\n",
        "# Prediction grid (includes extrapolation)\n",
        "X_pred = np.linspace(0, 10, 100)[:, None]\n",
        "\n",
        "# Two different prior means: zero vs constant (m=3)\n",
        "mean_zero = np.zeros(len(X_pred))\n",
        "mean_const = np.full(len(X_pred), 3.0)\n",
        "\n",
        "# Same covariance for both\n",
        "K = exp_quad_kernel(X_pred, X_pred, lengthscale=1.0, variance=1.0)\n",
        "K_obs = exp_quad_kernel(X_obs, X_obs, lengthscale=1.0, variance=1.0)\n",
        "K_cross = exp_quad_kernel(X_pred, X_obs, lengthscale=1.0, variance=1.0)\n",
        "noise = 0.1\n",
        "\n",
        "# GP posterior with zero mean\n",
        "K_obs_noise = K_obs + noise**2 * np.eye(len(X_obs))\n",
        "post_mean_zero = mean_zero + K_cross @ np.linalg.solve(K_obs_noise, y_obs - 0)\n",
        "\n",
        "# GP posterior with constant mean (same kernel!)\n",
        "post_mean_const = mean_const + K_cross @ np.linalg.solve(K_obs_noise, y_obs - 3.0)\n",
        "\n",
        "# Visualize\n",
        "fig = go.Figure()\n",
        "\n",
        "# Prior means\n",
        "fig.add_trace(go.Scatter(x=X_pred.flatten(), y=mean_zero, mode='lines',\n",
        "                         name='Prior: zero mean', line=dict(color='gray', dash='dash')))\n",
        "fig.add_trace(go.Scatter(x=X_pred.flatten(), y=mean_const, mode='lines',\n",
        "                         name='Prior: constant mean (3.0)', line=dict(color='lightblue', dash='dash')))\n",
        "\n",
        "# Posteriors\n",
        "fig.add_trace(go.Scatter(x=X_pred.flatten(), y=post_mean_zero, mode='lines',\n",
        "                         name='Posterior: zero mean', line=dict(color='darkblue', width=2)))\n",
        "fig.add_trace(go.Scatter(x=X_pred.flatten(), y=post_mean_const, mode='lines',\n",
        "                         name='Posterior: constant mean', line=dict(color='darkred', width=2)))\n",
        "\n",
        "# Data\n",
        "fig.add_trace(go.Scatter(x=X_obs.flatten(), y=y_obs, mode='markers',\n",
        "                         marker=dict(size=10, color='red', symbol='x'),\n",
        "                         name='Observed data'))\n",
        "\n",
        "# Shade extrapolation regions\n",
        "fig.add_vrect(x0=0, x1=X_obs.min(), fillcolor='lightyellow', opacity=0.3, layer='below', line_width=0)\n",
        "fig.add_vrect(x0=X_obs.max(), x1=10, fillcolor='lightyellow', opacity=0.3, layer='below', line_width=0)\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Mean Function Influence: Only Matters Without Data',\n",
        "    xaxis_title='x',\n",
        "    yaxis_title='f(x)',\n",
        "    height=400\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice the key pattern:\n",
        "\n",
        "- **In the shaded regions (no data)**: The two posteriors diverge, reverting to their respective prior means\n",
        "- **Near the data** (x â‰ˆ 2 to 8): The posteriors **nearly coincide** despite having very different prior means (0 vs 3)\n",
        "\n",
        "The mathematics explains why. The GP posterior mean is:\n",
        "\n",
        "$$\\mu_{\\text{post}}(x) = m(x) + k(x, X)^T [K + \\sigma^2 I]^{-1}(y - m(X))$$\n",
        "\n",
        "The key is the cross-covariance $k(x, X)$:\n",
        "- **Near data**: $k(x, X)$ is large â†’ data correction dominates â†’ prior mean $m(x)$ becomes irrelevant\n",
        "- **Far from data**: $k(x, X) \\to 0$ â†’ no correction â†’ posterior reverts to prior mean $m(x)$\n",
        "\n",
        "Even more striking: the **posterior covariance doesn't involve the mean function at all**:\n",
        "\n",
        "$$\\Sigma_{\\text{post}}(x, x') = k(x, x') - k(x, X)^T[K + \\sigma^2 I]^{-1} k(X, x')$$\n",
        "\n",
        "This is why we spent so much time on covariance functions and comparatively little on mean functions: the covariance function determines the posterior everywhere, while the mean function only matters in regions without data."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "default",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
